{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b944227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import sklearn\n",
    "import gensim\n",
    "import pickle\n",
    "from utils import *\n",
    "from processor import PreProcessor\n",
    "\n",
    "\n",
    "saveFileName = \"data/dialects.csv\"\n",
    "isDownload = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53890803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458197, 2)\n"
     ]
    }
   ],
   "source": [
    "dialects_df = readCSV(\"data/dialect_dataset.csv\")\n",
    "dialects_arr = np.array(dialects_df,dtype=\"str\")\n",
    "\n",
    "ids = dialects_arr[:,0]\n",
    "dialects = dialects_arr[:,1]\n",
    "print(dialects_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cd57259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458197, 3)\n"
     ]
    }
   ],
   "source": [
    "if isDownload:\n",
    "    tweets = get_tweets(ids)\n",
    "    print(tweets.shape)\n",
    "    \n",
    "    dialects_data = np.array([ids,tweets,dialects]).T\n",
    "    saveCSV(dialects_data,saveFileName,True)\n",
    "else:    \n",
    "    dialects_data = readCSV(saveFileName,True,\"str\")\n",
    "    \n",
    "np.random.shuffle(dialects_data)\n",
    "print(dialects_data.shape)\n",
    "\n",
    "ids,tweets,dialects = dialects_data[:,0],dialects_data[:,1],dialects_data[:,2]\n",
    "dataSize = dialects_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e430ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word2vec\n",
      "(458197, 18)\n",
      "id : 1156375592847233024\n",
      "tweet : @NadaAkkila1 لا ندى ، اكيد فرق كبير ، بس هالشخص نفسيته حلوه ، اسم الله ومتاكده انه مظلوم ماديا\n",
      "dialect : PL\n"
     ]
    }
   ],
   "source": [
    "preprocessor = PreProcessor(w2vPath = \"weights/full_grams_cbow_100_twitter.mdl\",isRemove = True)\n",
    "encodedDialects,no_classes,labels2idx,idx2labels = labelsEncoder(dialects)\n",
    "oneHotDialects = oneHotEncoder(encodedDialects,no_classes)\n",
    "print(oneHotDialects.shape)\n",
    "\n",
    "idx = np.random.randint(0,ids.shape[0])\n",
    "print(f\"id : {ids[idx]}\\ntweet : {tweets[idx]}\\ndialect : {dialects[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "721287f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " @USER لا ندى ، اكيد فرق كبير ، بس هالشخص نفسيته حلوه ، اسم الله ومتاكده انه مظلوم ماديا\n",
      " @USER https:///gomeogme/fmofw  @USER email@gmail.com  @USER \n",
      "  @USER\n"
     ]
    }
   ],
   "source": [
    "print(preprocessor.identifyMentions(tweets[idx]))\n",
    "print(preprocessor.identifyMentions(\"@imesS0852_boy https:///gomeogme/fmofw @1998 email@gmail.com @ahmedmohamed \\n @gn_494irnirhr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b88531d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@NadaAkkila1 لا ندى ، اكيد فرق كبير ، بس هالشخص نفسيته حلوه ، اسم الله ومتاكده انه مظلوم ماديا\n",
      "@imesS0852_boy  @URL  @1998 email@gmail.com  @URL  @ahmedmohamed \n",
      " @gn_494irnirhr  @URL \n"
     ]
    }
   ],
   "source": [
    "print(preprocessor.identifyURL(tweets[idx]))\n",
    "print(preprocessor.identifyURL(\"@imesS0852_boy https://www.google.com/in-go/123456:8080-98 @1998 email@gmail.com www.facebook.com @ahmedmohamed \\n @gn_494irnirhr www.youtube.com/video=15020\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "828e1f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@NadaAkkila1 لا ندى ، اكيد فرق كبير ، بس هالشخص نفسيته حلوه ، اسم الله ومتاكده انه مظلوم ماديا\n",
      " @HASH @imesS0852_boy https://www.google.com/in/123456:8080-98  @HASH @1998 email@gmail.com www.facebook.com @ahmedmohamed \n",
      " @gn_494irnirhr  @HASH \n"
     ]
    }
   ],
   "source": [
    "print(preprocessor.identifyHashTag(tweets[idx]))\n",
    "print(preprocessor.identifyHashTag(\"#hash1_2 @imesS0852_boy https://www.google.com/in/123456:8080-98 #hash2_3 @1998 email@gmail.com www.facebook.com @ahmedmohamed \\n @gn_494irnirhr #hash4_5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c1d0001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@NadaAkkila1 لا ندى  اكيد فرق كبير  بس هالشخص نفسيته حلوه  اسم الله ومتاكده انه مظلوم ماديا\n",
      "How are you doing \n",
      "says mohamed\n"
     ]
    }
   ],
   "source": [
    "print(preprocessor.removePunctuations(tweets[idx]))\n",
    "print(preprocessor.removePunctuations(\"'How are you doing ?!',\\nsays mohamed.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "832972c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@NadaAkkila1 لا ندى ، اكيد فرق كبير ، بس هالشخص نفسيته حلوه ، اسم الله ومتاكده انه مظلوم ماديا\n",
      "This is a smiley face  @EMOJI \n"
     ]
    }
   ],
   "source": [
    "print(preprocessor.identifyEmojis(tweets[idx]))\n",
    "print(preprocessor.identifyEmojis(u'This is a smiley face \\U0001f602'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96536252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before cleaning :  @AllTawfeeq\n",
      "كيف يعني\n",
      "\n",
      "غصب يرشحوا عربي\n",
      "after cleaning :  @USER كيف يعني غصب يرشحوا عربي\n",
      "@USER this is a cleaned tweet @EMOJI @USER from @URL @HASH\n"
     ]
    }
   ],
   "source": [
    "print(\"before cleaning : \", tweets[idx+3])\n",
    "print(\"after cleaning : \",preprocessor.cleanTweet(tweets[idx+3].lower()))\n",
    "print(preprocessor.cleanTweet(\"@mohamedessam98_20  this is a cleaned tweet \\U0001f602 ! @AIM ! from wwww.twitter.com. #CLEANTWEET\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "845ae5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedTweets = preprocessor.cleanTweets(tweets,isRemove=True)\n",
    "preprocessor.buildVocabulary(cleanedTweets,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c251b59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458197, 70)\n"
     ]
    }
   ],
   "source": [
    "tweetsTokens,masks = preprocessor.tokenizeTweets(cleanedTweets)\n",
    "print(tweetsTokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e2d3c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(446654, 100)\n"
     ]
    }
   ],
   "source": [
    "preTrainedEmbed = preprocessor.loadPreTrainedEmbeddings()\n",
    "print(preTrainedEmbed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e453d996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458197, 100)\n"
     ]
    }
   ],
   "source": [
    "sentVecs = preprocessor.sentToVec(tweetsTokens,preTrainedEmbed)\n",
    "print(sentVecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99942b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33694774 0.0798965  0.06166664 0.04466995 0.03656096 0.02677004\n",
      " 0.02385762 0.02223515 0.018316   0.01553069 0.01343988 0.01264321\n",
      " 0.01183316 0.01090182 0.01071412 0.00997094 0.00912391 0.0085606\n",
      " 0.00814308 0.00741792]\n",
      "[206.15690655 100.38769591  88.19455392  75.06272651  67.90870245\n",
      "  58.10869219  54.85676842  52.95862127  48.06533177  44.26005919\n",
      "  41.17316807  39.93422854  38.63375687  37.08226213  36.76164145\n",
      "  35.46375854  33.92400978  32.86008891  32.04873886  30.58847492]\n",
      "(458197, 20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=20)\n",
    "sentVecsRed = pca.fit_transform(sentVecs)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.singular_values_)\n",
    "print(sentVecsRed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bcdb838",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test,masks_train,masks_test = splitData(sentVecsRed,dialects,masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b71dcd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC trained on 320737 samples.\n",
      "{'train_time': 77.45333957672119, 'pred_time': 0.411144495010376, 'acc_train': 0.2718426623682332, 'acc_test': 0.2732358504292158}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "a\n",
    "model = LinearSVC()\n",
    "\n",
    "samples = len(Y_train)\n",
    "\n",
    "model,results = train_predict(model, samples, X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "pickle.dump(model,open('models/svm.pkl',\"wb\"))\n",
    "pickle.dump(pca,open('models/pca.pkl',\"wb\"))\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5068956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
