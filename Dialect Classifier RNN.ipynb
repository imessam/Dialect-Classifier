{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b944227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from utils import *\n",
    "from processor import PreProcessor\n",
    "from model import DialectClassifier\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "\n",
    "saveFileName = \"data/dialects.csv\"\n",
    "weightsPath = \"weights/full_grams_cbow_100_twitter.mdl\"\n",
    "isDownload = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53890803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458197, 2)\n"
     ]
    }
   ],
   "source": [
    "dialects_df = readCSV(\"data/dialect_dataset.csv\")\n",
    "dialects_arr = np.array(dialects_df,dtype=\"str\")\n",
    "\n",
    "ids = dialects_arr[:,0]\n",
    "dialects = dialects_arr[:,1]\n",
    "print(dialects_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cd57259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458197, 3)\n"
     ]
    }
   ],
   "source": [
    "if isDownload:\n",
    "    tweets = get_tweets(ids)\n",
    "    print(tweets.shape)\n",
    "    \n",
    "    dialects_data = np.array([ids,tweets,dialects]).T\n",
    "    saveCSV(dialects_data,saveFileName,True)\n",
    "else:    \n",
    "    dialects_data = readCSV(saveFileName,True,\"str\")\n",
    "    \n",
    "np.random.shuffle(dialects_data)\n",
    "print(dialects_data.shape)\n",
    "\n",
    "ids,tweets,dialects = dialects_data[:,0],dialects_data[:,1],dialects_data[:,2]\n",
    "dataSize = dialects_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e430ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word2vec\n",
      "(458197, 18)\n",
      "id : 1125049558495526784\n",
      "tweet : @numidie10 أنتى ق م ر ى .😍.هادو مغردين وخلاص😏😍😍😂❤\n",
      "dialect : LY\n"
     ]
    }
   ],
   "source": [
    "preprocessor = PreProcessor(w2vPath=weightsPath,isRemove = True)\n",
    "\n",
    "encodedDialects,no_classes,labels2idx,idx2labels = labelsEncoder(dialects)\n",
    "oneHotDialects = oneHotEncoder(encodedDialects,no_classes)\n",
    "print(oneHotDialects.shape)\n",
    "\n",
    "pickle.dump(idx2labels,open(\"idx2labels.pkl\",\"wb\"))\n",
    "\n",
    "idx = np.random.randint(0,ids.shape[0])\n",
    "print(f\"id : {ids[idx]}\\ntweet : {tweets[idx]}\\ndialect : {dialects[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "721287f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "قبل نقعد بال48 ساعه فايق المهم نرقد في الضي \n",
      "توا نرك فيها في عز الصهد والرطوبة وانفيق جوي فوق الريح\n",
      " @USER https:///gomeogme/fmofw  @USER email@gmail.com  @USER \n",
      "  @USER\n"
     ]
    }
   ],
   "source": [
    "print(preprocessor.identifyMentions(tweets[idx]))\n",
    "print(preprocessor.identifyMentions(\"@imesS0852_boy https:///gomeogme/fmofw @1998 email@gmail.com @ahmedmohamed \\n @gn_494irnirhr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b88531d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "قبل نقعد بال48 ساعه فايق المهم نرقد في الضي \n",
      "توا نرك فيها في عز الصهد والرطوبة وانفيق جوي فوق الريح\n",
      "@imesS0852_boy  @URL  @1998 email@gmail.com  @URL  @ahmedmohamed \n",
      " @gn_494irnirhr  @URL \n"
     ]
    }
   ],
   "source": [
    "print(preprocessor.identifyURL(tweets[idx]))\n",
    "print(preprocessor.identifyURL(\"@imesS0852_boy https://www.google.com/in-go/123456:8080-98 @1998 email@gmail.com www.facebook.com @ahmedmohamed \\n @gn_494irnirhr www.youtube.com/video=15020\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "828e1f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "قبل نقعد بال48 ساعه فايق المهم نرقد في الضي \n",
      "توا نرك فيها في عز الصهد والرطوبة وانفيق جوي فوق الريح\n",
      " @HASH @imesS0852_boy https://www.google.com/in/123456:8080-98  @HASH @1998 email@gmail.com www.facebook.com @ahmedmohamed \n",
      " @gn_494irnirhr  @HASH \n"
     ]
    }
   ],
   "source": [
    "print(preprocessor.identifyHashTag(tweets[idx]))\n",
    "print(preprocessor.identifyHashTag(\"#hash1_2 @imesS0852_boy https://www.google.com/in/123456:8080-98 #hash2_3 @1998 email@gmail.com www.facebook.com @ahmedmohamed \\n @gn_494irnirhr #hash4_5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c1d0001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "قبل نقعد بال48 ساعه فايق المهم نرقد في الضي \n",
      "توا نرك فيها في عز الصهد والرطوبة وانفيق جوي فوق الريح\n",
      "How are you doing \n",
      "says mohamed\n"
     ]
    }
   ],
   "source": [
    "print(preprocessor.removePunctuations(tweets[idx]))\n",
    "print(preprocessor.removePunctuations(\"'How are you doing ?!',\\nsays mohamed.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "832972c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "قبل نقعد بال48 ساعه فايق المهم نرقد في الضي \n",
      "توا نرك فيها في عز الصهد والرطوبة وانفيق جوي فوق الريح\n",
      "This is a smiley face  @EMOJI \n"
     ]
    }
   ],
   "source": [
    "print(preprocessor.identifyEmojis(tweets[idx]))\n",
    "print(preprocessor.identifyEmojis(u'This is a smiley face \\U0001f602'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96536252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before cleaning :  قبل نقعد بال48 ساعه فايق المهم نرقد في الضي \n",
      "توا نرك فيها في عز الصهد والرطوبة وانفيق جوي فوق الريح\n",
      "after cleaning :  قبل نقعد بال48 ساعه فايق المهم نرقد في الضي توا نرك فيها في عز الصهد والرطوبه وانفيق جوي فوق الريح\n",
      "@USER this is a cleaned tweet @EMOJI @USER from @URL @HASH\n"
     ]
    }
   ],
   "source": [
    "print(\"before cleaning : \", tweets[idx])\n",
    "print(\"after cleaning : \",preprocessor.cleanTweet(tweets[idx].lower()))\n",
    "print(preprocessor.cleanTweet(\"@mohamedessam98_20  this is a cleaned tweet \\U0001f602 ! @AIM ! from wwww.twitter.com. #CLEANTWEET\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "845ae5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedTweets = preprocessor.cleanTweets(tweets,isRemove=True)\n",
    "preprocessor.buildVocabulary(cleanedTweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c251b59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458197, 70)\n"
     ]
    }
   ],
   "source": [
    "tweetsTokens,masks = preprocessor.tokenizeTweets(cleanedTweets)\n",
    "print(tweetsTokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdf3c4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(446654, 100)\n"
     ]
    }
   ],
   "source": [
    "preTrainedEmbed = preprocessor.loadPreTrainedEmbeddings()\n",
    "print(preTrainedEmbed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bcdb838",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "hidden_dim = 128\n",
    "voc_len = preprocessor.LEN_VOC+1\n",
    "max_sen_len = preprocessor.MAX_SEN_LEN\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "\n",
    "\n",
    "X_train,X_test,Y_train,Y_test,masks_train,masks_test = splitData(tweetsTokens,oneHotDialects,masks,splitPercent = 0.7)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae500e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3509/3509 [==============================] - 185s 51ms/step - loss: 1.8667 - accuracy: 0.4187 - val_loss: 1.6242 - val_accuracy: 0.4949\n",
      "Epoch 2/10\n",
      "3509/3509 [==============================] - 177s 50ms/step - loss: 1.0857 - accuracy: 0.6677 - val_loss: 1.6949 - val_accuracy: 0.4917\n",
      "Epoch 3/10\n",
      "3509/3509 [==============================] - 177s 50ms/step - loss: 0.6426 - accuracy: 0.8062 - val_loss: 1.9725 - val_accuracy: 0.4769\n",
      "Epoch 4/10\n",
      "3509/3509 [==============================] - 178s 51ms/step - loss: 0.4447 - accuracy: 0.8646 - val_loss: 2.2831 - val_accuracy: 0.4686\n",
      "Epoch 5/10\n",
      "3509/3509 [==============================] - 177s 50ms/step - loss: 0.3392 - accuracy: 0.8959 - val_loss: 2.5448 - val_accuracy: 0.4653\n",
      "Epoch 6/10\n",
      "3509/3509 [==============================] - 177s 51ms/step - loss: 0.2809 - accuracy: 0.9115 - val_loss: 2.7919 - val_accuracy: 0.4596\n",
      "Epoch 7/10\n",
      "3509/3509 [==============================] - 178s 51ms/step - loss: 0.2412 - accuracy: 0.9239 - val_loss: 2.9837 - val_accuracy: 0.4590\n",
      "Epoch 8/10\n",
      "3509/3509 [==============================] - 177s 51ms/step - loss: 0.2123 - accuracy: 0.9326 - val_loss: 3.1317 - val_accuracy: 0.4525\n",
      "Epoch 9/10\n",
      "3509/3509 [==============================] - 178s 51ms/step - loss: 0.1943 - accuracy: 0.9379 - val_loss: 3.2753 - val_accuracy: 0.4545\n",
      "Epoch 10/10\n",
      "3509/3509 [==============================] - 178s 51ms/step - loss: 0.1764 - accuracy: 0.9436 - val_loss: 3.4014 - val_accuracy: 0.4546\n"
     ]
    }
   ],
   "source": [
    "dialectClassifier = DialectClassifier(voc_len,max_sen_len,embed_dim,hidden_dim,no_classes)\n",
    "dialectClassifier.compile(optimizer = optimizer,loss = loss, metrics = \"accuracy\")\n",
    "hist = dialectClassifier.fit(X_train,Y_train,batch_size = batch_size,\n",
    "                             epochs = epochs,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aebe3a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4296/4296 [==============================] - 26s 6ms/step - loss: 3.3843 - accuracy: 0.4580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.3842661380767822, 0.45801687240600586]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialectClassifier.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65d139d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/dialectClassifierRNN\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/dialectClassifierRNN\\assets\n"
     ]
    }
   ],
   "source": [
    "dialectClassifier.save('models/dialectClassifierRNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abcf809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
